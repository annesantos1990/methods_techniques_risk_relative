# methods_techniques_risk_relative
Reposit√≥rio com a descri√ß√£o dos principais m√©todos e t√©cnicas utilizadas nesse projeto

<details>

<summary> <h2> 1. Risco Relativo </h2></summary>

Para o caso desse projeto, ser√° analisado se, por exemplo, para uma vari√°vel como a idade, uma determinada faixa et√°ria apresenta maior risco de inadimpl√™ncia que outra, identificando se certos grupos s√£o mais propensos a n√£o cumprir com suas obriga√ß√µes financeiras.  Esses grupos s√£o os quartis da amostra, segmentados previamente como mostrado em **C√°lculo dos quartis**: 

<details> <summary> <h4> C√°lculo dos quartis </h4>  - Clique em ‚ñ∂ para ver os detalhes </summary> 

****

Aqui, foi obtida a segmenta√ß√£o das seguintes vari√°veis em quartis:

**age | last_month_salary | number_dependents | total_loan | total_90_days_overdue | using lines not secured personal assets | debt_ratio**

O c√≥digo utilizado para a segmenta√ß√£o foi o seguinte:

```sql
  SELECT *,
    NTILE(4) OVER (ORDER BY age) AS age_quartiles,
    NTILE(4) OVER (ORDER BY last_month) AS last_month_quartiles,
    NTILE(4) OVER (ORDER BY number_dependents) AS number_dependents_quartiles,
    NTILE(4) OVER (ORDER BY total_loan) AS total_loan_quartiles,
    NTILE(4) OVER (ORDER BY total_90_days_overdue) AS total_90_days_overdue_quartiles,
    NTILE(4) OVER (ORDER BY total_lines) AS total_lines_quartiles,
    NTILE(4) OVER (ORDER BY debt_ratio) AS debt_ratio_quartiles
  FROM `dados_proj3.proj3_unified_table2`
```
</details>

O c√°lculo do risco relativo ser√° feito para cada quartil, conforme a f√≥rmula:

$$
ùëÖùëÖ_{Q_n}= \tau_{Q_n}/\tau_{Q_x, Q_y, Q_z}
$$

Onde, 

$\tau_{Q_n}$ √© a taxa de inadimpl√™ncia do quartil *n*

$\tau_{Q_x, Q_y, Q_z}$ √© a taxa de inadimpl√™ncia dos outros quartis.

Para o c√°lculo de Risco Relativo no Big Query, foi utilizado o seguinte racioc√≠nio:

$\tau_{Q_1}$ √© calculado como a m√©dia da vari√°vel *default_flag* no quartil *n*. Como a vari√°vel *default_flag* tem valor 1 para inadimplentes e 0 para adimplentes, a soma dessa vari√°vel dentro do quartil 1, dividida pelo n√∫mero de observa√ß√µes no quartil, nos d√° a taxa de inadimpl√™ncia para aquele grupo:

$$
\tau_{Q_n}= media(\textup{default flag(Qn)})
$$

e

$$
\tau_{Q_x, Q_y, Q_z}= \frac{\sum (\textup{default flag}) - \Sigma (\textup{default flag (Qn)})}{N-N_{Qn}}
$$

Onde,

- $\sum (\textup{default flag})$ √© a soma total dos valores da vari√°vel default_flag.
- $\Sigma (\textup{default flag (Qn)}$ √© a soma dos valores da vari√°vel default_flag no quartil n.
- $N$ √© o n√∫mero total de observa√ß√µes na amostra.
- $N_{Qn}$ √© o n√∫mero de observa√ß√µes no quartil *n*.

Esse c√°lculo nos permitir√° comparar a taxa de inadimpl√™ncia do quartil n com os outros quartis, ajudando a identificar se existe um grupo de cada vari√°vel com maior risco de inadimpl√™ncia.

O risco relativo e a classifica√ß√£o dos grupos foram feitas em um mesmo c√≥digo e ser√° melhor detalhado abaixo:

```sql
-- Dividindo os dados em quartis com NTILE
WITH quartiles_table AS (
  SELECT *,
    NTILE(4) OVER (ORDER BY age) AS age_quartiles,
    NTILE(4) OVER (ORDER BY last_month) AS last_month_quartiles,
    NTILE(4) OVER (ORDER BY number_dependents) AS number_dependents_quartiles,
    NTILE(4) OVER (ORDER BY total_loan) AS total_loan_quartiles,
    NTILE(4) OVER (ORDER BY total_90_days_overdue) AS total_90_days_overdue_quartiles,
    NTILE(4) OVER (ORDER BY total_lines) AS total_lines_quartiles,
    NTILE(4) OVER (ORDER BY debt_ratio) AS debt_ratio_quartiles
  FROM `dados_proj3.proj3_unified_table2`
),

total_measurements AS (
  SELECT
    SUM(default_flag) AS sum_default,
    COUNT(*) AS total
  FROM quartiles_table
),

age_relative_risks AS (
  SELECT
    age_quartiles AS quartile,
    min(age) AS lower_age,
    max(age) AS upper_age,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY age_quartiles, total_measurements.sum_default, total_measurements.total
),

last_month_relative_risks AS (
  SELECT
    last_month_quartiles AS quartile,
    min(last_month) AS lower_last_month,
    max(last_month) AS upper_last_month,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY last_month_quartiles, total_measurements.sum_default, total_measurements.total
),

number_dependents_relative_risks AS (
  SELECT
    number_dependents_quartiles AS quartile,
    min(number_dependents) AS lower_number_dependents,
    max(number_dependents) AS upper_number_dependents,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY number_dependents_quartiles, total_measurements.sum_default, total_measurements.total
),

total_loan_relative_risks AS (
  SELECT
    total_loan_quartiles AS quartile,
    min(total_loan) AS lower_total_loan,
    max(total_loan) AS upper_total_loan,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY total_loan_quartiles, total_measurements.sum_default, total_measurements.total
),

total_90_days_overdue_relative_risks AS (
  SELECT
    total_90_days_overdue_quartiles AS quartile,
    min(total_90_days_overdue) AS lower_total_90_days_overdue,
    max(total_90_days_overdue) AS upper_total_90_days_overdue,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY total_90_days_overdue_quartiles, total_measurements.sum_default, total_measurements.total
),

total_lines_relative_risks AS (
  SELECT
    total_lines_quartiles AS quartile,
    min(total_lines) AS lower_total_lines,
    max(total_lines) AS upper_total_lines,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY total_lines_quartiles, total_measurements.sum_default, total_measurements.total
),

debt_ratio_relative_risks AS (
  SELECT
    debt_ratio_quartiles AS quartile,
    min(debt_ratio) AS lower_debt_ratio,
    max(debt_ratio) AS upper_debt_ratio,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY debt_ratio_quartiles, total_measurements.sum_default, total_measurements.total
)

SELECT 
  a.quartile AS quartiles,
  a.relative_risk AS age_relative_risk,
  a.lower_age,
  a.upper_age,
  CASE
    WHEN a.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN a.relative_risk > 1 THEN 'Grupo de Risco'
  END AS age_classification,

  b.relative_risk AS last_month_relative_risk,
  b.lower_last_month,
  b.upper_last_month,
  CASE
    WHEN b.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN b.relative_risk > 1 THEN 'Grupo de Risco'
  END AS last_month_classification,

  c.relative_risk AS number_dependents_relative_risk,
  c.lower_number_dependents,
  c.upper_number_dependents,
  CASE
    WHEN c.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN c.relative_risk > 1 THEN 'Grupo de Risco'
  END AS number_dependents_classification,

  d.relative_risk AS total_loan_relative_risk,
  d.lower_total_loan,
  d.upper_total_loan,
  CASE
    WHEN d.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN d.relative_risk > 1 THEN 'Grupo de Risco'
  END AS total_loan_classification,
  
  e.relative_risk AS total_90_days_overdue_relative_risk,
  e.lower_total_90_days_overdue,
  e.upper_total_90_days_overdue,
  CASE
    WHEN e.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN e.relative_risk > 1 THEN 'Grupo de Risco'
  END AS total_90_days_overdue_classification,

  f.relative_risk AS total_lines_relative_risk,
  f.lower_total_lines,
  f.upper_total_lines,
  CASE
    WHEN f.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN f.relative_risk > 1 THEN 'Grupo de Risco'
  END AS total_lines_classification,
  
  g.relative_risk AS debt_ratio_relative_risk,
  g.lower_debt_ratio,
  g.upper_debt_ratio,
  CASE
    WHEN g.relative_risk < 1 THEN 'Grupo que n√£o apresenta risco'
    WHEN g.relative_risk > 1 THEN 'Grupo de Risco'
  END AS debt_ratio_classification

FROM 
  age_relative_risks a
  JOIN last_month_relative_risks b ON a.quartile = b.quartile
  JOIN number_dependents_relative_risks c ON a.quartile = c.quartile
  JOIN total_loan_relative_risks d ON a.quartile = d.quartile
  JOIN total_90_days_overdue_relative_risks e ON a.quartile = e.quartile
  JOIN total_lines_relative_risks f ON a.quartile = f.quartile
  JOIN debt_ratio_relative_risks g ON a.quartile = g.quartile
ORDER BY a.quartile;

```

Embaixo, detalho as tabelas auxiliares feitas e o que elas representam:

**quartiles_table:**

Nessa tabela foi obtida a segmenta√ß√£o em quartis das oito vari√°veis (**age | last_month_salary | number_dependents | total_loan | total_90_days_overdue | using lines not secured personal assets | debt_ratio).**

**total_measurements:**

Nessa tabela, foi feita a soma da vari√°vel default_flag ($\sum (\textup{default flag})$) e a contagem do total de linhas da tabela unificada (Para o c√°lculo de $*N*$. 

```sql
total_measurements AS (
  SELECT
    SUM(default_flag) AS sum_default,
    COUNT(*) AS total
  FROM quartiles_table
),
```

Onde,

SUM(default_flag) AS sum_default √© $\sum (\textup{default flag})$

COUNT(*) AS total √© $N$

***vari√°vel*_risks:**

Foram constru√≠das um total de oito tabelas auxiliares, uma para cada vari√°vel para o c√°lculo do risco relativo de cada quartil. Ex.:

```sql
age_relative_risks AS (
  SELECT
    age_quartiles AS quartile,
    a.lower_age,
	  a.upper_age,
    AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk
  FROM quartiles_table, total_measurements
  GROUP BY age_quartiles, total_measurements.sum_default, total_measurements.total
),
```

Onde,

- AVG(default_flag) √© $\tau_{Q_n}= media(\textup{default flag(Qn)})$
- ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) √© $\tau_{Q_x, Q_y, Q_z}$
- AVG(default_flag) / ((total_measurements.sum_default - SUM(default_flag)) / (total_measurements.total - COUNT(*))) AS relative_risk √© $RR$

No final, foram agrupadas todas as tabelas pelos quartiles de cada um, usando o comando JOIN e os $RR$ de cada vari√°vel foi classificado de acordo com essa tabela:

| RR | Interpreta√ß√£o |
| --- | --- |
| =1 | aus√™ncia¬†de associa√ß√£o |
| <1 | fator de prote√ß√£o |
| >1 | fator de risco |

Usando o comando CASE. Ex:

```sql
  CASE
    WHEN a.relative_risk < 1 THEN 'Sem Risco de Inadimpl√™ncia'
    WHEN a.relative_risk > 1 THEN 'Risco de Inadimpl√™ncia'
  END AS age_classification,
```
**Tabela com a segmenta√ß√£o dos grupos de acordo com cada vari√°vel:
| quartis | last_month relative_risk | last_month (min) | last_month (max) | last_month classification | number_dependents relative_risk | number_dependents (min) | number_dependents (max) | number_dependents classification | total_lines relative_risk | total_lines (min) | total_lines (max) | total_lines classification | debt_ratio relative_risk | debt_ratio (min) | debt_ratio (max) | debt_ratio classification |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | 1,949529054 | 0 | R$3944,00 | Risco de Inadimpl√™ncia | 0,658798838 | 0 | 0 | Sem Risco de Inadimpl√™ncia | 0,039086483 | 0 | 0,028829832 | Sem Risco de Inadimpl√™ncia | 0,746959956 | 0 | 0,181105577 | Sem Risco de Inadimpl√™ncia |
| 2 | 0,961747393 | R$3947,00 | R$5400,00 | Sem Risco de Inadimpl√™ncia | 0,769668123 | 0 | 0 | Sem Risco de Inadimpl√™ncia | 0,004830737 | 0,028830012 | 0,144361012 | Sem Risco de Inadimpl√™ncia | 0,823739618 | 0,181122062 | 0,369246406 | Sem Risco de Inadimpl√™ncia |
| 3 | 0,987142489 | R$5400,00 | R$7495,00 | Sem Risco de Inadimpl√™ncia | 1,101057634 | 0 | 1 | Risco de Inadimpl√™ncia | 0,146706137 | 0,144373673 | 0,529282357 | Sem Risco de Inadimpl√™ncia | 1,453406147 | 0,369278625 | 0,881271543 | Risco de Inadimpl√™ncia |
| 4 | 0,392771434 | R$7495,00 | R$1560100,00 | Sem Risco de Inadimpl√™ncia | 1,596238587 | 1 | 13 | Risco de Inadimpl√™ncia | 46,1104476 | 0,52937284 | 22000 | Risco de Inadimpl√™ncia | 1,047840157 | 0,881365417 | 307001 | Risco de Inadimpl√™ncia |
</details>

<details> <summary> <h2>2. Modelo de Classifica√ß√£o Risco de Cr√©dito Baseado no Risco Relativo </h2> </summary>

### Classifica√ß√£o com base nos Scores

Aqui, o objetivo √© classificar os clientes como  ‚ÄúMau pagador‚Äù e ‚ÄúBom pagador‚Äù  de acordo com todas as vari√°veis dispon√≠veis no banco de dados. Essa classifica√ß√£o, tem como prop√≥sito modelar meu banco de dados para que se possa avaliar futuros clientes de acordo com as diferentes vari√°veis do meu modelo.

Afim de obter essa classifica√ß√£o, as categorias ‚ÄúMau pagador‚Äù e ‚ÄúBom pagador‚Äù de cada uma das 7 vari√°veis foi convertida em vari√°veis Dummies:

- Mau pagador = 1
- Bom pagador = 0

Parte do c√≥digo, somente com as classifica√ß√µes:

```sql
SELECT 
  a.user_id,
  a.default_flag,
  h.relative_risk AS age_relative_risk,
  a.age_quartiles,
  h.lower_age,
  h.upper_age,
  CASE
    WHEN h.relative_risk < 1 THEN 0 ELSE 1
  END AS age_risk_dummy,

  b.relative_risk AS last_month_relative_risk,
  a.last_month_quartiles,
  b.lower_last_month,
  b.upper_last_month,
  CASE
    WHEN b.relative_risk < 1 THEN 0 ELSE 1
  END AS last_month_risk_dummy,

  c.relative_risk AS number_dependents_relative_risk,
  a.number_dependents_quartiles,
  c.lower_number_dependents,
  c.upper_number_dependents,
  CASE
    WHEN c.relative_risk < 1 THEN 0 ELSE 1
  END AS number_dependents_risk_dummy,

  d.relative_risk AS total_loan_relative_risk,
  a.total_loan_quartiles,
  d.lower_total_loan,
  d.upper_total_loan,
  CASE
    WHEN d.relative_risk < 1 THEN 0 ELSE 1
  END AS total_loan_risk_dummy,
  
  e.relative_risk AS total_90_days_overdue_relative_risk,
  a.total_90_days_overdue_quartiles,
  e.lower_total_90_days_overdue,
  e.upper_total_90_days_overdue,
  CASE
    WHEN e.relative_risk < 1 THEN 0 ELSE 1
  END AS total_90_days_overdue_risk_dummy,

  f.relative_risk AS total_lines_relative_risk,
  a.total_lines_quartiles,
  f.lower_total_lines,
  f.upper_total_lines,
  CASE
    WHEN f.relative_risk < 1 THEN 0 ELSE 1
  END AS total_lines_risk_dummy,
  
  g.relative_risk AS debt_ratio_relative_risk,
  a.debt_ratio_quartiles,
  g.lower_debt_ratio,
  g.upper_debt_ratio,
  CASE
    WHEN g.relative_risk < 1 THEN 0 ELSE 1
  END AS debt_ratio_risk_dummy

FROM 
  quartiles_table a
  JOIN age_relative_risks h ON a.age_quartiles = h.quartile
  JOIN last_month_relative_risks b ON a.last_month_quartiles = b.quartile
  JOIN number_dependents_relative_risks c ON a.number_dependents_quartiles = c.quartile
  JOIN total_loan_relative_risks d ON a.total_loan_quartiles = d.quartile
  JOIN total_90_days_overdue_relative_risks e ON a.total_90_days_overdue_quartiles = e.quartile
  JOIN total_lines_relative_risks f ON a.total_lines_quartiles = f.quartile
  JOIN debt_ratio_relative_risks g ON a.debt_ratio_quartiles = g.quartile
),
```

Assim, foi poss√≠vel somar os valores dummies, no qual o score final, chamado de risk_score, poderia ter um valor de de 0 a 7.

```sql
-- Calculando a pontua√ß√£o final
final_scores AS (
  SELECT *,
    (age_risk_dummy + last_month_risk_dummy + number_dependents_risk_dummy + total_loan_risk_dummy + total_90_days_overdue_risk_dummy + total_lines_risk_dummy + debt_ratio_risk_dummy) AS risk_score
  FROM risk_classification
),
```

 Com esses valores em m√£os foi estabelecido um valor de corte para a vari√°vel risk_score, no qual, acima desse valor, o cliente seria classificado como ‚Äúmau pagador‚Äù e abaixo como ‚Äúbom pagador‚Äù.

O valor de corte foi determinado pelo valor da taxa de inadimpl√™ncia para cada um dos poss√≠veis risk_score. A taxa de inadimpl√™ncia ($\tau_i$ ) foi calculada dividindo o somat√≥rio do *default_flag* para cada risk_score pelo quantidade total de valores da vari√°vel *default_flag*. 

$$
\tau_i=\frac{\sum(\text{default flag)}_i}{N}
$$

Onde, 

- $N$ √© o n√∫mero total de observa√ß√µes na amostra.

C√≥digo:

```sql
-- Calcular a taxa de inadimpl√™ncia para cada faixa de pontua√ß√£o
risk_distribution AS (
  SELECT
    risk_score,
    --COUNT(*) AS total_users,
    --SUM(default_flag) AS total_defaults,
    SUM(default_flag) / COUNT(*) AS default_rate
  FROM final_scores
  GROUP BY risk_score
  ORDER BY risk_score
),
```

Com esse c√°lculo temos a taxa de inadimpl√™ncia para cada grupo de risk_score. Os valores encontrados, se encontram na tabela abaixo:

| risk_score | $\tau_i $ |
| --- | --- |
| 1 | 0.00018601190476190475 |
| 2 | 0.0019365250134480904 |
| 3 | 0.00579496364977347 |
| 4 | 0.022197201222454561 |
| 5 | 0.07903780068728522 |
| 6 | 0.17396449704142011 |
| 7 | 0.255813953488 |

Baseado no valor das taxas $\tau_i$  pra 

Nesse c√≥digo foi utilizado o seguinte crit√©rio de classifica√ß√£o:

taxa > 0.1:  ‚ÄúMau pagador‚Äù 

Taxa < 0.1: ‚ÄúBom pagador‚Äù

Essa classifica√ß√£o foi adicionada na tabela como a vari√°vel ***risk_class.***

```sql
classified_users AS (
  SELECT risk_score,
    default_rate,
    CASE
      WHEN default_rate >= 0.1 THEN 'Mau Pagador'
      ELSE 'Bom Pagador'
    END AS risk_class
  FROM risk_distribution
)

-- Visualizar a distribui√ß√£o e taxa de inadimpl√™ncia para cada faixa de pontua√ß√£o
SELECT *
FROM final_scores final
JOIN  classified_users class ON final.risk_score = class.risk_score

```



### Valida√ß√£o do Modelo

Agora, para testar se essa classifica√ß√£o prev√™ bem o risco de cr√©dito, foi utilizado a matriz de confus√£o no Google Colab.

A matriz de confus√£o √© uma m√©trica de performance dos algoritmos de classifica√ß√£o. Vamos utiliz√°-la para testar esse modelo:

No Google Colab, exportei os dados da tabela com todas as vari√°veis dummy, assim como o risk_score e a vari√°vel  ***risk_class*** com a classifica√ß√£o do cliente como ‚ÄúBons pagadores‚Äù e ‚ÄúMaus pagadores‚Äù

![1_ql1siLJsgfdmnabD4Jy8kg](https://github.com/annesantos1990/limpezadedados_spotify/assets/166059836/c7f6cdce-ed99-451b-8aa4-d416aa8a14ca)

Feito isso, a vari√°vel risk_class foi reclassificada em valores num√©ricas, onde Mau Pagador recebeu valor 1 e Bons Pagadores recebeu valor 0:

```python
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Definir o ponto de corte e calcular a coluna 'predicted_default'
cut_off = 3  # Ajuste conforme necess√°rio
df3['predicted_default'] = df3['risk_class'].apply(lambda x: 1 if x == "Mau Pagador" else 0)
```

E essa nova vari√°vel, no qual tem as informa√ß√µes do nosso modelo de classifica√ß√£o foi comparada com a vari√°vel default_flag que j√° √© a vari√°vel com as informa√ß√µes dos adimplentes e inadimplentes.

Assim, podemos avaliar se o modelo de classifica√ß√£o constru√≠do para detectar ‚ÄúBons Pagadores‚Äù e ‚ÄúMaus Pagadores‚Äù √© um bom modelo.

Para avaliar o desempenho do modelo, foi utilizado a matriz de confus√£o, que fornece informa√ß√µes sobre a precis√£o das previs√µes em rela√ß√£o aos valores reais. A classifica√ß√£o √© separada em valores positivos e negativos. Para esclarecer melhor, vejamos alguns exemplos:

- Verificar se o modelo detecta corretamente uma pessoa tem c√¢ncer:
    - Tem c√¢ncer (positivo), n√£o tem c√¢ncer (negativo)
- Detec√ß√£o de cachorro e gatos em fotografias:
    - gato (positivo), cachorro (negativo - n√£o √© um gato)

Como pode-se observar, o crit√©rio para determinar o que √© positivo ou negativo varia conforme o caso. No entanto, o negativo pode ser interpretado como a nega√ß√£o do positivo.

Para o nosso caso, consideramos que positivo √© um ‚Äúbom pagador‚Äù e negativo √© um ‚Äúmau pagador‚Äù.

- Falsos negativos seriam bons pagadores sendo classificados como maus pagadores;
- Falsos positivo seriam maus pagadores sendo classificados como bons pagadores;

Junto com a matriz de confus√£o tamb√©m tem outras m√©tricas que tamb√©m s√£o avaliadas como:

- Acur√°cia: A propor√ß√£o de todas as previs√µes corretas (positivas e negativas) em rela√ß√£o ao total de previs√µes;;
- Precis√£o: A propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de previs√µes positivas. Isto mede a exatid√£o das previs√µes positivas do modelo;
- Recall: A propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de casos realmente positivos. Isto mede a capacidade do modelo de identificar corretamente todos os casos positivos;
- F1-score: Uma medida que equilibra a precis√£o e o recall, calculada como a m√©dia harm√¥nica dessas duas m√©tricas.

Para o meu modelo de classifica√ß√£o, √© importante que eu diminua os falsos positivos ou falsos negativos?

- Falsos positivos: Mal pagador sendo classificado como Bom pagador
- Falsos positivos: Bom pagador sendo classificado como Mau pagador

Se eu quero reduzir a probabilidade de inadimpl√™ncias e perdas, temos que focar em diminuir os falsos positivos.

![1_ql1siLJsgfdmnabD4Jy8kg.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/75dcc154-fd1d-4af5-b505-98330c057cd2/7e1c104d-a06d-45e7-a476-33fc1991848a/1_ql1siLJsgfdmnabD4Jy8kg.jpg)

- Assim, o **ppv** (**Positive Predictive Value (PPV) ou precis√£o)**¬†precisa dar alto, porque teremos menos falsos positivos, aumentando a precis√£o positiva
- E o **recall da vari√°vel negativa** precisa  ser elevado, porque, entre todos os valores verdadeiramente negativos, precisamos que haja poucos falsos positivos (significando que o modelo previu um valor positivo quando, na verdade, √© verdadeiramente negativo).

Na linguagem do nosso modelo, isso significa que:

- O ppv precisa ser alto, porque teremos menos maus Pagadores sendo classificado como bons pagadores, aumentando a precis√£o das previs√µes positiva.
- E o recall da vari√°vel negativa precisa ser alto, porque, entre todos os valores verdadeiramente de maus Pagadores, preciso que haja poucos maus pagadores sendo classificado como bons pagadores.

Em resumo, queremos que nosso modelo detecte bem os maus pagadores e nos traga poucos falsos positivos, garantindo que os bons pagadores n√£o sejam erroneamente classificados como maus pagadores.

C√≥digo para avaliar o modelo com a matriz de confus√£o e as m√©tricas supracitadas:

```python
# Vari√°vel real e predita
# Aqui default_flag √© a vari√°vel real, pois ela j√° nos traz a informa√ß√£o se um cliente √© inadimplente ou adimplente
# E temos o nosso modelo que √© a vari√°vel "predicted_default"
y_true = df['default_flag']
y_pred = df3['predicted_default']

# Matriz de confus√£o para avaliar se meu modelo com a nova vari√°vel "predicted_default" √© um bom modelo.
conf_matrix = confusion_matrix(y_true, y_pred)

# Relat√≥rio de classifica√ß√£o
class_report = classification_report(y_true, y_pred)

print("Matriz de Confus√£o:")
print(conf_matrix)
print("\nRelat√≥rio de Classifica√ß√£o:")
print(class_report)

# Visualizar a matriz de confus√£o
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Bom Pagador', 'Mau Pagador'], yticklabels=['Bom Pagador', 'Mau Pagador'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Matriz de Confus√£o')
plt.show()
```
</details>

<details> <summary> <h2>3. Regress√£o Log√≠stica </h2></summary>

A modelo de regress√£o log√≠stica foi proposto como uma alternativa ao modelo anterior, que n√£o alcan√ßou m√©tricas de desempenho satisfat√≥rias. 

A regress√£o log√≠stica √© um modelo de classifica√ß√£o onde as vari√°veis preditoras s√£o cont√≠nuas e a vari√°vel resposta √© bin√°ria, geralmente codificada como 0 ou 1. Este modelo √© √∫til para prever a probabilidade de ocorr√™ncia de um evento com base nas vari√°veis independentes.

O c√≥digo utilizado para a regress√£o log√≠stica e a avalia√ß√£o das m√©tricas do modelo encontra-se abaixo:

```python
# Selecionar as vari√°veis independentes e dependentes
X = df[['age', 'last_month', 'number_dependents', 'total_90_days_overdue', 'debt_ratio', 'total_loan']]
y = df['default_flag']
```

```python
# Convertendo y para inteiro.
y = y.astype(int)

# Certifique-se de que y s√≥ cont√©m valores bin√°rios (0 e 1)
print(y.unique())
```

```python
# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
```

Foram utilizadas tr√™s t√©cnicas diferentes no modelo de Regress√£o Log√≠stica:

1. Class Weight
    
    O par√¢metro `class_weight='balanced'` na fun√ß√£o de regress√£o log√≠stica do Python foi utilizado para lidar com o problema das classes desbalanceadas na vari√°vel `default_flag`. Este par√¢metro ajusta automaticamente o peso das classes inversamente proporcional √†s suas frequ√™ncias na amostra de dados de treinamento. Em outras palavras, a fun√ß√£o de custo √© ajustada para penalizar mais os erros cometidos nas classes minorit√°rias e menos os erros nas classes majorit√°rias. Isso ajuda o modelo a considerar a import√¢ncia relativa das classes minorit√°rias durante o treinamento, resultando em uma melhor performance na predi√ß√£o dessas classes.
    
2. Oversampling
    
    √â uma t√©cnica de reamostragem no qual tem com prop√≥sito equilibrar a diferen√ßa de classes aumentando o n√∫mero de inst√¢ncias da classe minorit√°ria.
    
3. Undersampling
    
    √â uma t√©cnica de reamostragem no qual tem com prop√≥sito equilibrar essa diferen√ßa diminuindo o n√∫mero de inst√¢ncias da classe majorit√°ria.
    

Para ver cada uma delas, acessar o Google Colab: https://colab.research.google.com/drive/1UTQUppbQ1UxoRsXbzcXoNZf4f_LWFN_I?usp=sharing

A que teve maior quantidade de acertos de *Maus Pagadores*, mas ainda assim com boas m√©tricas foi a primeira. Abaixo est√° o c√≥digo:

```python
# Inicializar e treinar o modelo de regress√£o log√≠stica com ajuste de pesos das classes
model = LogisticRegression(class_weight='balanced', max_iter=500)
model.fit(X_train, y_train)

# Fazer previs√µes
y_pred = model.predict(X_test)

# Avaliar o modelo
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Acur√°cia do modelo:", accuracy)
print("Relat√≥rio de classifica√ß√£o:\n", report)

# Calcular e exibir a matriz de confus√£o
conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto: Bom Pagador', 'Previsto: Mau Pagador'], yticklabels=['Real: Bom Pagador', 'Real: Mau Pagador'])
plt.xlabel('Classe Prevista')
plt.ylabel('Classe Verdadeira')
plt.title('Matriz de Confus√£o')
plt.show()
```

Conforme discutido na Se√ß√£o 2, neste projeto a prioridade foi diminuir os falsos positivos e ter tamb√©m boa quantidade de acertos de *Maus Pagadores*. Por isso, o formato de regress√£o log√≠stica com o ***Class Weight*** foi o escolhido, pois ele teve os fatores supracitados.




Para mais detalhes acessar o [Notebook do Google Colab](https://colab.research.google.com/drive/1UTQUppbQ1UxoRsXbzcXoNZf4f_LWFN_I?usp=sharing).

</details>
